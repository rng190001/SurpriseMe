# -*- coding: utf-8 -*-
"""Mansi's Copy of WithFilterWithOneUserQuery.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14J7iqlPu0crQUR3DyfwonsSpZBuP2Iig
"""

def calculate_tf_idf(word, gift_descriptions, gift_word_counts, word_document_counts):
    # Calculate TF-IDF any given word
    tf_idfs = dict()

    # Go through each gift and calculate the word's tf-idf in relation to that gift
    for key, value in gift_word_counts.items():
        # If this word is used to describe this gift, calculate its tf-idf
        if word in value:
            # TF = # of times word is used for gift description/total number of terms for this gift description
            term_frequency = gift_word_counts[key][word]/(len(gift_descriptions[key]))

            # IDF = log(# of gifts in dataset/# of gifts containing word in its description)
            inverse_doc_frequency = math.log10(len(gift_descriptions)/word_document_counts[word])

            tf_idfs[key] = (term_frequency * inverse_doc_frequency)
        else:
            # If the word is not used to describe the gift, don't add it to the tf-idf dictionary
            # tf_idfs[key] = 0
            continue

    # After calculating the tf-idfs for every gift and the given word, sort in descending
    # order to see the highest tf-idfs at the top
    sorted_tf_idfs = dict(sorted(tf_idfs.items(), key=lambda item: item[1], reverse=True))

    for key, value in sorted_tf_idfs.items():
        print(key, "- description ", gift_descriptions[key], " with TF-IDF: ", value)

    return sorted_tf_idfs

def get_document_counts(giftDescriptions):
    # Create a dictionary where key: word, value: list of giftIDs
    document_counts_for_word = dict()

    # For each word in a gift description, create a list of giftIDs that it is used to describe
    for key, value in giftDescriptions.items():
        for word in value:
            # If the key (current giftID) is not in the giftID list for the word, add it
            if word in document_counts_for_word and key not in document_counts_for_word[word]:
                document_counts_for_word[word] += [key]
            # If the key already is in the giftID list, move on
            elif word in document_counts_for_word and key in document_counts_for_word[word]:
                continue
            else:
            # Otherwise, make a new entry for the word and a corresponding giftID list as the value
                document_counts_for_word[word] = [key]

    # Replace the list of giftIDs that the word occurs in with the length of the list,
    # allowing us to know how many gift descriptions the word occurs in
    for key, value in document_counts_for_word.items():
        document_counts_for_word[key] = len(value)

    ''' TO TEST
    i = 0
    for key, value in document_counts_for_word.items():
        i += 1
        print(key, value)
        if i == 50:
            break
    '''

    return document_counts_for_word

def get_word_counts(giftDescriptions):
    # Create a dictionary where key: gift ID, value: dictionary of word counts
    gift_word_counts = dict()

    # Go through the description of each gift
    for key, value in giftDescriptions.items():
        # Create a dictionary at the value
        gift_word_counts[key] = dict()
        # Get the counts of each word for that specific gift description
        for word in value:
            if word in gift_word_counts[key]:
                gift_word_counts[key][word] += 1
            else:
                gift_word_counts[key][word] = 1

        ''' TO TEST
        i = 0
        for key, value in word_counts.items():
            i += 1
            print(key, value)
            if i == 30:
                break
        '''

    return gift_word_counts

def get_wordnet_pos(tree_tag):
    # Assign Verb tag
    if tree_tag.startswith('V'):
        return wordnet.VERB
    # Assign Noun tag
    elif tree_tag.startswith('N'):
        return wordnet.NOUN
    # Assign Adjective tag
    elif tree_tag.startswith('J'):
        return wordnet.ADJ
    # Assign Adverb tag
    elif tree_tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

def preprocess_data(text):
    # Create lemmatizer
    lemmatizer = WordNetLemmatizer()

    # Remove all punctuation, set all words to lower case, and split by spaces
    cleaned_sentence = re.sub(r'[^\w\s-]', ' ',text).lower()
    cleaned_sentence = re.split(r'\s+', cleaned_sentence.strip())

    # Now store all words that are not stopwords
    no_stopwords = [word for word in cleaned_sentence if word not in stopwords and len(word) > 2]

    # Assign Part of Speech tags to each token
    POS_tags = pos_tag(no_stopwords)
    POS_tags = [(word, 'VBG') if word.endswith('ing') else (word, pos) for word, pos in pos_tag(no_stopwords)]

    # Lemmatize the words
    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in POS_tags]

    return lemmatized_words

def calculate_cosine_similarity(vector1, vector2):
    # Calculate the dot product and magnitudes
    dot_product = sum(vector1[word] * vector2[word] for word in vector1 if word in vector2)
    magnitude1 = math.sqrt(sum(value**2 for value in vector1.values()))
    magnitude2 = math.sqrt(sum(value**2 for value in vector2.values()))

    if not magnitude1 or not magnitude2:
        return 0.0
    return dot_product / (magnitude1 * magnitude2)

def create_tf_idf_matrix(gift_descriptions, gift_word_counts, word_document_counts):
    tf_idf_matrix = {}
    for gift_id, word_counts in gift_word_counts.items():
        tf_idf_vector = calculate_tf_idf_vector(word_counts, gift_descriptions[gift_id], word_document_counts)
        tf_idf_matrix[gift_id] = tf_idf_vector
    return tf_idf_matrix

def calculate_tf_idf_vector(word_counts, description, word_document_counts):
    total_terms = sum(word_counts.values())
    tf_idf_vector = {}
    for word in word_counts:
        term_frequency = word_counts[word] / total_terms
        inverse_document_frequency = math.log10(len(description) / word_document_counts[word]) if word in word_document_counts else 0
        tf_idf_vector[word] = term_frequency * inverse_document_frequency
    return tf_idf_vector

def find_similar_gifts(gift_id, tf_idf_matrix):
    target_vector = tf_idf_matrix[gift_id]
    similarities = {}
    for other_id, vector in tf_idf_matrix.items():
        if other_id != gift_id:
            similarity = calculate_cosine_similarity(target_vector, vector)
            similarities[other_id] = similarity
    # Sort by similarity score in descending order
    return dict(sorted(similarities.items(), key=lambda item: item[1], reverse=True)[:10])

def ask_question(prompt):
    return input(f"{prompt}\nYou: ")

import pandas as pd
import nltk
import re
import math
from nltk import word_tokenize
from nltk import sent_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords, wordnet
from nltk import pos_tag
from sklearn.metrics.pairwise import cosine_similarity
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
stopwords = set(stopwords.words('english'))

def split_database_by_holiday(gift_data, holiday):
    """Splits gift database by specified holiday."""
    if holiday.lower() == "christmas":
        return gift_data[gift_data['Holiday'].str.contains("Christmas", case=False)]
    elif holiday.lower() == "anniversary":
        return gift_data[gift_data['Holiday'].str.contains("Anniversary", case=False)]
    return gift_data

def split_database_by_gender(gift_data, gender):
    """Splits gift database by specified holiday."""
    if gender.lower() == "male":
        return gift_data[gift_data['Gender'].str.contains(r"\bMale\b", case=False, regex=True)]
    elif gender.lower() == "female":
        return gift_data[gift_data['Gender'].str.contains(r"\bFemale\b", case=False, regex=True)]
    return gift_data

def recommend_gifts_based_on_input(user_input, gift_data):

    # Preprocess input
    cleaned_input = preprocess_data(user_input)
    #print(cleaned_input)

    # Split database by holiday
    if "christmas" in cleaned_input:
        filtered_data = split_database_by_holiday(gift_data, "Christmas")
    elif "anniversary" in cleaned_input:
        filtered_data = split_database_by_holiday(gift_data, "Anniversary")
    else:
        filtered_data = gift_data

    # Split database by gender
    male_keywords = {"male", "man", "boy", "boyfriend", "husband", "nephew", "grandson", "brother", "uncle", "father", "dad", "grandpa"}
    female_keywords = {"female", "woman", "girl", "girlfriend", "wife", "niece", "granddaughter", "sister", "aunt", "mother", "mom", "grandma"}
    if set(cleaned_input) & male_keywords:
        gender_filtered_data = split_database_by_gender(filtered_data, "Male")
    elif set(cleaned_input) & female_keywords:
        gender_filtered_data = split_database_by_gender(filtered_data, "Female")
    else:
        gender_filtered_data = filtered_data

    # Combine gift titles and summaries for vectorization
    gender_filtered_data['CombinedText'] = (gender_filtered_data['Gift Title'] + " " + gender_filtered_data['Gift Summary'] + " " + (gender_filtered_data['Relationship'] + " ") + " " + ((gender_filtered_data['Associated Hobbies'] + " ")*5)).apply(preprocess_data)

    # Get the word counts of every word in the description of each gift
    gift_word_counts = get_word_counts(gender_filtered_data['CombinedText'])

    # Get the number of documents that each word occurs in
    word_document_counts = get_document_counts(gender_filtered_data['CombinedText'])

    # Create TF-IDF matrix
    tf_idf_matrix = create_tf_idf_matrix(gender_filtered_data['CombinedText'], gift_word_counts, word_document_counts)

    # Compute TF-IDF vector for user input
    user_input_counts = {token: cleaned_input.count(token) for token in cleaned_input}
    user_tf_idf_vector = calculate_tf_idf_vector(user_input_counts, gender_filtered_data['CombinedText'], word_document_counts)

    # Calculate similarity scores
    similarity_scores = [
        calculate_cosine_similarity(user_tf_idf_vector, tf_idf_matrix[gift_id])
        for gift_id in tf_idf_matrix
    ]

    # Add similarity scores to the dataframe
    gender_filtered_data['Similarity'] = similarity_scores

    # Sort by similarity score and return top recommendations
    recommendations = gender_filtered_data.sort_values(by='Similarity', ascending=False).head(10)

    return recommendations

def main():
    while True:
        print("\nWelcome to the Gift Finder! Please input your option.")
        print("1. Find a gift!")
        print("2. Exit")

        # Get user input
        choice = input("Please enter your choice (1 or 2): ").strip()

        if choice == '1':
            # Logic for finding a new gift
            find_new_gift()
        elif choice == '2':
            print("Thank you for using the Gift Finder! Goodbye!")
            break
        else:
            print("Invalid input. Please choose 1 or 2.")

def find_new_gift():
    print("\nLet's find a new gift!")
    # Add your logic for finding a new gift here
    user_input = input("Describe the gift or holiday preferences in one sentence: ")
    recommendations = recommend_gifts_based_on_input(user_input, preprocessed_giftsData)

    print("Top 10 gift recommendations based on your input:")
    for _, row in recommendations.iterrows():
        print(f"Gift ID: {row['Gift ID']} Title: {row['Gift Title']}, Similarity: {row['Similarity']:.4f}")

# Example usage
if __name__ == "__main__":
    giftsFile = "./giftDB.csv"
    giftsData = pd.read_csv(giftsFile).dropna()

    #Preprocess data --> Mansi
    preprocessed_giftsData = giftsData.copy()
    main()

    #user_input = input("Describe the gift or holiday preferences in one sentence: ")
    #recommend_gifts_based_on_input(user_input, preprocessed_giftsData)

